Current goal:

  - Maybe some simple compiler optimizations.

Bugs to fix:

  - Why does the UI crash after the "get a mirror on self" thing?

What compiler optimizations could I try first?

  - The most important ones, I'm guessing, will be the ones that help us avoid block cloning. That's causing us a lot of grief, with contorting the GC code and a lot of extra time spent in GC and stuff. So I think we're gonna want to:
    - Avoid cloning failblocks passed to primitives.
    - Do that type prediction thing where it knows that the call to ifTrue:False: is likely to be true or false, so it inlines those ones.
    - General inlining.
  - But ask Dave. He'll have ideas.

Speeding up the export cycle would be really nice. What's the strategy for that?

  - Speed up incremental update? (I don't really understand why it's slow. Try profiling it.)
  - Fix incremental update so that it can continue to work indefinitely.

Cleanups to do:

  - Addresses. Factor it all so that I can easily switch to untagged addresses.
  - Factor the layout stuff so that it's a bit more uniform and elegant about handling oops versus addresses. (C is really nice in that way; how close can we get to that?)
  - Stuff that tries to avoid cloning... is there a way to make it clear which stuff that is? Draw a clear fence around it? And avoid duplication with regular stuff? (The problem is that there's some stuff that needs failblocks when running on a remote image, but needs to avoid cloning when running in a local image.)

----

Dave's comments:

  - The most important optimization is inlining. It's a big one (and don't forget that it affects the debugger), but after that the regular optimization stuff is less important. (It can be addictive, though, so be careful not get sucked into doing just one more optimization.)
  - If I'm looking to port something to the iPhone, I might want to try the real Self VM, scary as it is.


----

For inlining, I think I need to:
  - Find the place where the compiler generates IR nodes for a send, and make sure the compiler knows when it knows the type of the receiver.
  - Think of a simple heuristic for deciding when to inline. Maybe "if it's a data slot or if the method is small", for now.
  - Find the places where the compiler creates IR nodes referring to the receiver or arguments or locals. Make sure they don't just do it by name, and then indirect them through a currentScope thing or something.

----

There's gotta be a way to avoid having to pull in the whole object table every time anything changes in it. Why not just pull in the parts we're accessing?

----

Remember to clean up the aaaaa things.

----

Stuff I want to do:

  - In the allocator, maybe initialize it right away with a vector of all 32 precolored register values. Then use those in the locationAssigner. (I think that's what the textbook wants me to do; maybe it makes a difference?)
  - Turn the miniVM into a really good test of the basic VM's capabilities. And unify that stuff with the midiVM/selfVM tests AND with the Self "tests" object.
  - Fix the compilerTester. Right, right - I broke it, made it require the compilationRequester.

----

http://selflanguage.org/_static/published/dynamic-deoptimization.pdf

So it looks like the deal is:

  - The compiler has to create scopeDesc information describing how the virtual stack frames are laid out within the physical stack frame.
  - Just to display the stack, no deoptimization is necessary - the debugger just has to pretend that the source-level stack frames are there (which it can do because of the scopeDesc info).
  - To deoptimize the topmost activation, just save a copy of the physical frame, pop it off, and then use the scopeDesc info to recreate source-level ones.
  - To deoptimize an activation in the middle of the stack, just wait for the stack to unwind back to that point and then deoptimize it. (Do that by making the return PC actually be to a procedure that'll deoptimize the thing.)
  - Need to have unoptimized nmethods either created on-the-fly or lying around, so that we can switch the PC into the right place in the unoptimized one and continue execution.
  - Use interrupt points (sends and backward branches) to interrupt a process. (They happen frequently, so there shouldn't be any major delay when you open up a debugger on a running process.) That way we can do source-level single-stepping by deoptimizing and then just setting the interrupt register. In between interrupt points, you can do any optimizations that won't wreck the ability to reconstruct the stack info at the next interrupt point.

That doesn't look so scary. And since we don't have source-level single-stepping or runtime changes yet anyway, I won't be breaking anything if I just implement inlining and make sure that the debugger can display stuff right. Cool!

----

Hey, if I wanted to experiment with heap-allocated activations, so that I could compare the speed, how hard would that be? To make it easy to switch back and forth? (Or maybe even to have them both side by side?)

----

Inlining plan:

  - Inline other sends where we know the receiver type, not just self-sends.
  - In particular, inline block methods, so that we can eliminate the block.
  - Inline methods containing blocks. (The problem is that the block needs to be customized for each type of enclosing nmethod, since the enclosing nmethod might put the uplevel values in different places.) How about I have each nmethod keep a vector of the blocks that it uses (and clone each one of them from the original block literal)? And then add a constant VM slot to every block, containing a pointer to its value nmethod (or maybe to the enclosing nmethod)? (See forReflecteeOf:AddAllMappedVMSlotsTo:Mapper:.) That'll make sure that each block has a different map. Then I've just gotta make sure each one gets the right nmethod in its nmethod cache.
  - Flesh out the list of stuff that needs to be pre-inlined to make the system ramp up quickly enough.

----

The irNodeGenerator needs to know, when it comes across a send, whether it can inline that send or not. Which means it needs to know whether we know the type of the receiver or not.

How can we know the type of the receiver? Well, if the rcvrValue is valueForSelf, that's cool. If not... then we need to find all the definers of the rcvrValue. We can do that by... wait, why can't we just do the thing where we go through each node and have it add itself to the "definers" of each value that it defines? Oh, because of move nodes?

Bleh, hold on. I wanna get the move-node-coalescing thing working. That might solve a lot of this for me.

OK, I'm a bit closer to having coalescing working, but it's not quite there yet. I don't think it's gonna solve the problem, though, so let's not worry about it yet.

I need to either follow the data flow backwards from each use until I reach a def along every control-flow path... or I need to convert to SSA form or something. Is that right? How do I do that, exactly?

----

OK! Now I've got a problem because the compiler isn't smart enough to know that the start-node's definition of the memoized-block value doesn't actually reach any of the uses of the block.

SSA would fix this. Can I just create two separate values with the same location? Yeah, one that's defined by the start node and used by the block-literal node (and the return nodes?), and one that's defined by the block-literal node and used by whoever uses the block (well, I guess that means the move to the stack value) and the return nodes.

Except... the locationAssigner has no way of knowing that they both need to be in the same location. Wait, why do they, again?

The way block literals work is that we memoize them, so that we don't end up cloning the block more than once (which would be an error), and don't end up cloning it at all if it's not used (which would be inefficient). The block-literal node might see either 0 or the block, and so might the return nodes, but the move node that pushes the cloned block will only see the actual block.

OK, so I need one of those phi functions! There are three values here: v1, v2, v3.
  - v1 is defined by the start node and used by the phi node.
  - v2 is defined by the block node and used by the move-to-a-stack-value node and by the phi node.
  - v3 is defined by the phi node and used by the block node and the return nodes.

So where does this phi node go, and how does it work? Well, it goes... um... before the block node? Hmm, and maybe there's a fourth one that goes before the return node?

Yeah, maybe. So there'd be a phi node immediately before the block-literal node. It... what does it do? Does it move v1 and v2 to v3? I don't get it, how does it know which one to move there?

Hey, wait, couldn't I use the locationAssigner's alias mechanism?

Yeah, that's exactly what it's for.

Blecch, this isn't gonna work. I can't just put in a hack for the blocks - I'm gonna have this problem with locals, too. So let's do a general solution. But let's do it *after* I fix this inlining thing.
